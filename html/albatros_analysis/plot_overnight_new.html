<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>albatros_analysis.plot_overnight_new API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>albatros_analysis.plot_overnight_new</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os, sys
import matplotlib as mpl

if os.environ.get(&#34;DISPLAY&#34;, &#34;&#34;) == &#34;&#34;:
    print(&#34;no display found. Using non-interactive Agg backend&#34;)
    mpl.use(&#34;Agg&#34;)
from matplotlib import pyplot as plt
import numpy as np
from scio import scio # module scio with class called scio, packeged as pbio, make sure `pip import pbio` not `scio`
import SNAPfiletools as sft
import argparse
import time, re
from datetime import datetime 
import matplotlib.dates as mdates
from multiprocessing import Pool
from functools import partial
import pytz


def get_ts_from_name(f):
    return int(f.split(&#34;/&#34;)[-1])


def get_localtime_from_UTC(tstamp, mytz):
    return datetime.fromtimestamp(int(tstamp), tz=pytz.utc).astimezone(tz=mytz)


# ============================================================
def get_data_arrs(data_dir: str, ctime_start: str, ctime_stop: str, chunk_time, blocklen, mytz):
    &#34;&#34;&#34;
    Given the path to a Big data directory (i.e. directory contains the directories
    labeled by the first 5 digits of the ctime date), gets all the data in some time interval.

    Parameters:
    -----------

    data_dir: str
        path to data directory

    ctime_start, ctime_stop: str
        desired start and stop time in ctime

    chunk_time: ??
    
    blocklen: (probably int)
    
    mytz: (what kind of object is this? probably pytz.tzfile)
        Timezone (of the dish at collection?)

    Returns:
    --------

    cimte_start, ctime_stop: int
        start and stop times in ctime

    pol00,pol11,pol01r,pol01i: array
        2D arrays containing the data for given time interval for autospectra
        as well as cross spectra. pol00 corresponds to adc0 and pol11 to adc3
    &#34;&#34;&#34;
    print(&#34;\n################### READING DATA ###################&#34;)
    print(f&#34;Files requested between timestamps {ctime_start} to {ctime_stop}&#34;)
    print(
        f&#34;Corresponding UTC time: {datetime.utcfromtimestamp(ctime_start)} to {datetime.utcfromtimestamp(ctime_stop)}&#34;
    )

    # all the dirs between the timestamps. read all, append, average over chunk length
    data_subdirs = sft.time2fnames(ctime_start, ctime_stop, data_dir)
    print(&#34;total data subdirs&#34;, len(data_subdirs))
    print(&#34;First and last subdirs:&#34;, data_subdirs[0], data_subdirs[-1])
    data_subdirs.sort()

    if len(data_subdirs) == 0:
        print(&#34;NOTHING WAS READ. CHECK TSTAMPS&#34;)
        sys.exit(1)

    # rough estimate of number of rows we&#39;ll read
    nrows_guess = len(data_subdirs) * ((int(3600 / chunk_time / blocklen) + 1) + 1)
    # print(&#34;Starting with a guess of &#34;, nrows_guess)
    print(&#34;guessed rows&#34;, nrows_guess)
    pol00 = np.zeros((nrows_guess + 500, 2048))

    nrows = 0

    t1 = time.time()
    new_dirs = [d + &#34;/pol00.scio.bz2&#34; for d in data_subdirs]
    datpol00 = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol11.scio.bz2&#34; for d in data_subdirs]
    datpol11 = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol01r.scio.bz2&#34; for d in data_subdirs]
    datpol01r = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol01i.scio.bz2&#34; for d in data_subdirs]
    datpol01i = scio.read_files(new_dirs)
    print(time.time() - t1, f&#34;Read {len(data_subdirs)} files&#34;)

    # average everything if blocklen&gt;1
    # print(&#34;first row must be in:&#34;, data_subdirs[0])

    myavgfunc = partial(get_avg, block=blocklen)
    if blocklen &gt; 1:
        t1 = time.time()
        with Pool(os.cpu_count()) as p:
            avgpol00 = p.map(myavgfunc, datpol00)
            avgpol11 = p.map(myavgfunc, datpol11)
            avgpol01r = p.map(myavgfunc, datpol01r)
            avgpol01i = p.map(myavgfunc, datpol01i)
        print(time.time() - t1, &#34;averaged everything&#34;)
    else:
        avgpol00 = datpol00
        avgpol11 = datpol11
        avgpol01r = datpol01r
        avgpol01i = datpol01i

    print(len(avgpol00))
    t1 = time.time()
    tstart = 0
    tend = 0
    for i, d in enumerate(avgpol00):
        # print(&#34;Mean, median are&#34;, np.mean(d,axis=0),np.median(d,axis=0))
        print(&#34;working on&#34;, data_subdirs[i])
        if d is None:
            continue
        if i == 0:
            pol00[: d.shape[0]] = d
            nrows += d.shape[0]
            ts = get_ts_from_name(data_subdirs[i])

            tstart = ts  # save starting time for user output
            ts = ts + d.shape[0] * chunk_time * blocklen
            continue
        newts = get_ts_from_name(data_subdirs[i])
        diff = int((newts - ts) / chunk_time / blocklen)
        # each cell in the plot represents a minimum time of blocklen * chunktime.
        # That&#39;s the time resolution for the plot. Can&#39;t catch gaps &lt; resolution.
        if diff &gt; 0:
            print(f&#34;significant diff b/w files {tstart} and {newts} of:&#34;, diff, &#34;rows&#34;)
            pol00[nrows : nrows + diff, :] = np.nan
            pol00 = np.append(pol00, np.zeros((diff, 2048)), axis=0)
            nrows += diff
        # print(nrows, d.shape)
        # print(nrows,nrows+d.shape[0],pol00.shape,&#34;heh&#34;)
        pol00[nrows : nrows + d.shape[0], :] = d
        nrows += d.shape[0]
        # print(&#34;reading&#34;, data_subdirs[i], &#34;with size &#34;, d.shape[0], &#34;NROWS&#34;, oldnrows,nrows)
        tstart = newts
        ts = newts + d.shape[0] * chunk_time * blocklen
    tend = ts
    # print(&#34;HERE&#34;)
    # once we have pol00, we know the exact size. use it
    tstart = get_ts_from_name(
        data_subdirs[0]
    )  # tstart was replaced above for missing gap info
    print(&#34;############################################################&#34;)
    print(
        f&#34;First file at: {tstart}, Last file at: {get_ts_from_name(data_subdirs[-1])}&#34;
    )
    print(f&#34;Plotting all data starting {tstart} and ending {int(tend)}&#34;)
    ts, te = list(map(partial(get_localtime_from_UTC, mytz=mytz), [tstart, tend]))
    print(
        f&#34;In Local time: {ts.strftime(&#39;%b-%d %H:%M:%S&#39;)} to {te.strftime(&#39;%b-%d %H:%M:%S&#39;)} in {mytz.zone}&#34;
    )
    print(&#34;Final nrows:&#34;, nrows)

    pol00 = pol00[:nrows].copy()
    # print(pol00.shape)

    pol11 = np.zeros((nrows, 2048))
    pol01r = np.zeros((nrows, 2048))
    pol01i = np.zeros((nrows, 2048))

    nrows = 0
    for i in range(len(avgpol00)):
        if (avgpol11[i] is None) or (avgpol01i[i] is None) or (avgpol01r[i] is None):
            continue
        if i == 0:
            r = avgpol11[i].shape[0]
            pol11[:r, :] = avgpol11[i]
            pol01r[:r, :] = avgpol01r[i]
            pol01i[:r, :] = avgpol01i[i]
            nrows += r
            ts = get_ts_from_name(data_subdirs[i]) + r * chunk_time * blocklen
            continue
        newts = get_ts_from_name(data_subdirs[i])
        diff = int((newts - ts) / chunk_time / blocklen)
        if diff &gt; 0:
            pol11[nrows : nrows + diff, :] = np.nan
            pol01r[nrows : nrows + diff, :] = np.nan
            pol01i[nrows : nrows + diff, :] = np.nan
            nrows += diff
        r = avgpol11[i].shape[0]
        pol11[nrows : nrows + r, :] = avgpol11[i]
        pol01r[nrows : nrows + r, :] = avgpol01r[i]
        pol01i[nrows : nrows + r, :] = avgpol01i[i]
        nrows += r
        ts = newts + r * chunk_time * blocklen

    t2 = time.time()
    # print(&#39;Time taken to concatenate data:&#39;,t2-t1)
    # print(&#34;pol00, pol11,pol01r, pol01i shape:&#34;, pol00.shape,pol11.shape,pol01r.shape,pol01i.shape)
    pol00 = np.ma.masked_invalid(pol00)
    pol11 = np.ma.masked_invalid(pol11)
    pol01r = np.ma.masked_invalid(pol01r)
    pol01i = np.ma.masked_invalid(pol01i)
    return pol00, pol11, pol01r, pol01i, tstart, tend


def get_avg(arr, block=10):
    &#34;&#34;&#34;
    Fast average array over a given block size.
    &#34;&#34;&#34;
    if arr is None:
        return None
    iters = arr.shape[0] // block
    leftover = arr.shape[0] % block
    # print(iters,leftover)
    nrows = iters + int(leftover &gt; 0)
    ncols = arr.shape[1]
    newarr = np.zeros((nrows, ncols), dtype=arr.dtype)
    cmp1 = np.median(arr[0, :]) / np.median(
        arr[1, :]
    )  # temporary fix, assuming only first row is expected to be faulty
    if cmp1 &gt; 1e2:
        # skip first row before averaging for first block
        newarr[0, :] = np.mean(arr[1:block, :], axis=0)
        newarr[1:iters, :] = np.mean(
            arr[block : iters * block, :].reshape(-1, block, ncols), axis=1
        )
    else:
        # print(f&#34;Shape of passed arr {arr.shape} and shape of new arr {newarr.shape}&#34;)
        newarr[:iters, :] = np.mean(
            arr[: iters * block, :].reshape(-1, block, ncols), axis=1
        )
    if leftover:
        newarr[iters, :] = np.mean(arr[iters * block :, :], axis=0)
    return newarr


def get_stats(data_arr):
    &#34;&#34;&#34;
    Given a 2D array containing some data chunk, returns the
    min, median, mean, and max over that chunk.
    &#34;&#34;&#34;
    # print(&#34;WHERE MIN ZERO&#34;,np.where(np.min(data_arr,axis=0)==0))
    # print(&#34;WHERE MEDIAN ZERO&#34;,np.where(np.median(data_arr,axis=0)==0))
    # print(&#34;MEDIAN&#34;,np.median(data_arr,axis=0))
    # print(&#34;MEDIAN MA&#34;,np.ma.median(data_arr,axis=0))
    if logplot:
        stats = {
            &#34;min&#34;: np.log10(np.ma.min(data_arr, axis=0)),
            &#34;median&#34;: np.log10(np.ma.median(data_arr, axis=0)),
            &#34;mean&#34;: np.log10(np.ma.mean(data_arr, axis=0)),
            &#34;max&#34;: np.log10(np.ma.max(data_arr, axis=0)),
        }
    else:
        stats = {
            &#34;min&#34;: np.ma.min(data_arr, axis=0),
            &#34;median&#34;: np.ma.median(data_arr, axis=0),
            &#34;mean&#34;: np.ma.mean(data_arr, axis=0),
            &#34;max&#34;: np.ma.max(data_arr, axis=0),
        }
    return stats


def get_vmin_vmax(data_arr):
    &#34;&#34;&#34;
    Automatically gets vmin and vmax for colorbar
    &#34;&#34;&#34;
    # print(&#34;shape of passed array&#34;, data_arr.shape, data_arr.dtype)
    xx = data_arr[~data_arr.mask].data
    med = np.percentile(xx, 50)
    # print(med, &#34;median&#34;)
    u = np.percentile(xx, 99)
    b = np.percentile(xx, 1)
    xx_clean = xx[(xx &lt;= u) &amp; (xx &gt;= b)]  # remove some outliers for better plotting
    stddev = np.std(xx_clean)
    vmin = max(med - 2 * stddev, 10**7)
    vmax = med + 2 * stddev
    # print(&#34;vmin, vmax are&#34;, vmin, vmax)
    return vmin, vmax


def get_ylim_times(t_i, t_f):
    &#34;&#34;&#34;
    Gets the y limits in matplotlib&#39;s date format for a given initial time
    and final time. t_i and t_f must be given in ctime
    &#34;&#34;&#34;
    # getlocaltime = lambda tstamp: datetime.fromtimestamp(int(tstamp),tz=pytz.utc).astimezone(tz=mytz)
    y_lims = list(map(datetime.utcfromtimestamp, [t_i, t_f]))
    y_lims_plt = mdates.date2num(y_lims)
    # date2num is NOT tz aware.
    # will return same value regardless of tz of passed datetime object.
    # pass tz to formatter and tick locators
    return y_lims_plt


# ================= plotting functions =======================
def full_plot(data_arrs, mytz, chunk_time):
    &#34;&#34;&#34;
    Makes a plot that contains autospectra waterfalls for each pol, as well
    as some statistics (min,max,med,mean spectra), and cross spectra
    &#34;&#34;&#34;
    global vmin, vmax, vmin2, vmax2
    pol00, pol11, pol01, tstart, tend = data_arrs
    print(&#34;Generating stats for pol00&#34;)
    pol00_stats = get_stats(pol00)
    print(&#34;Generating stats for pol11&#34;)
    pol11_stats = get_stats(pol11)
    # print(&#34;WHERE POL11 ZERO&#34;, np.where(pol11==0))
    # print(&#34;Pol00 median&#34;, pol00_stats[&#39;median&#39;])
    if logplot is True:
        pol00 = np.log10(pol00)
        pol11 = np.log10(pol11)

    if rescale:
        scaling_pol00 = np.tile(pol00_stats[&#34;median&#34;], pol00.shape[0]).reshape(
            *pol00.shape
        )
        scaling_pol11 = np.tile(pol11_stats[&#34;median&#34;], pol11.shape[0]).reshape(
            *pol11.shape
        )
        pol00[:] = 10 * (
            pol00 - scaling_pol00
        )  # - instead of / for type 2 scaling: log(pol00/pol00_median)
        pol11[:] = 10 * (pol11 - scaling_pol11)
        vmin = -1
        vmax = 1
        vmin2 = vmin
        vmax2 = vmax

    y_extent = get_ylim_times(tstart, tend)
    ticks = np.linspace(y_extent[0], y_extent[1], 10)
    # print(y_extent)

    myext = np.array([freq[0], freq[-1], y_extent[1], y_extent[0]])

    plt.figure(figsize=(18, 10), dpi=200)
    plt.subplot(2, 3, 1)

    plt.imshow(pol00, vmin=vmin, vmax=vmax, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol00&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated log(power)&#34;, rotation=90)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.yticks(ticks)
    ax = plt.gca()
    ax.yaxis.set_major_formatter(datetimefmt)

    # this makes the code slow on Lab laptop.

    # nticks = 15 #desired number of ticks on the plot
    # hourinterval = int(pol00.shape[0]*chunk_time*blocksize/3600/nticks)
    # locator=mdates.HourLocator(interval=hourinterval,tz=mytz)
    # ax.yaxis.set_major_locator(locator)

    plt.subplot(2, 3, 4)
    plt.imshow(pol11, vmin=vmin2, vmax=vmax2, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol11&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated log(power)&#34;, rotation=90)
    plt.yticks(ticks)
    ax = plt.gca()
    ax.yaxis.set_major_formatter(datetimefmt)
    # ax.yaxis.set_major_locator(locator)

    plt.subplot(2, 3, 2)
    plt.title(&#34;Median power in frequency bins&#34;)
    plt.plot(freq, pol00_stats[&#34;max&#34;], &#34;r-&#34;, label=&#34;Max&#34;)
    plt.plot(freq, pol00_stats[&#34;min&#34;], &#34;b-&#34;, label=&#34;Min&#34;)
    plt.plot(freq, pol00_stats[&#34;mean&#34;], &#34;k-&#34;, label=&#34;Mean&#34;)
    plt.plot(
        freq, pol00_stats[&#34;median&#34;], color=&#34;#666666&#34;, linestyle=&#34;-&#34;, label=&#34;Median&#34;
    )
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.ylabel(&#34;pol00&#34;)
    plt.legend(loc=&#34;lower right&#34;, fontsize=&#34;small&#34;)
    plt.ylim(vmin, vmax)

    plt.subplot(2, 3, 5)
    plt.plot(freq, pol11_stats[&#34;max&#34;], &#34;r-&#34;, label=&#34;Max&#34;)
    plt.plot(freq, pol11_stats[&#34;min&#34;], &#34;b-&#34;, label=&#34;Min&#34;)
    plt.plot(freq, pol11_stats[&#34;mean&#34;], &#34;k-&#34;, label=&#34;Mean&#34;)
    plt.plot(
        freq, pol11_stats[&#34;median&#34;], color=&#34;#666666&#34;, linestyle=&#34;-&#34;, label=&#34;Median&#34;
    )
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.ylabel(&#34;pol11&#34;)
    plt.ylim(vmin2, vmax2)

    plt.legend(loc=&#34;lower right&#34;, fontsize=&#34;small&#34;)

    plt.subplot(2, 3, 3)
    plt.imshow(np.log10(np.abs(pol01)), vmin=3, vmax=8, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol01 magnitude&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated power&#34;, rotation=90)
    plt.gca().set_yticklabels([])

    plt.subplot(2, 3, 6)
    plt.imshow(
        np.angle(pol01),
        vmin=-np.pi,
        vmax=np.pi,
        aspect=&#34;auto&#34;,
        extent=myext,
        cmap=&#34;RdBu&#34;,
    )
    plt.title(&#34;pol01 phase&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Radian&#34;, rotation=90)
    plt.gca().set_yticklabels([])

    range_localtime = list(
        map(partial(get_localtime_from_UTC, mytz=mytz), [tstart, tend])
    )
    print(&#34;start and end times are&#34;, tstart, tend)
    plt.suptitle(
        f&#39;Plotting {range_localtime[0].strftime(&#34;%b-%d %H:%M:%S&#34;)} to {range_localtime[1].strftime(&#34;%b-%d %H:%M:%S&#34;)} in {mytz.zone} \nAveraged over {blocksize} chunks ~ {blocksize*chunk_time/60:4.2f} minutes.&#39;
    )
    plt.tight_layout()
    outfile = os.path.join(
        outdir,
        &#34;direct_overnight_output&#34;
        + &#34;_&#34;
        + str(ctime_start)
        + &#34;_&#34;
        + str(ctime_stop)
        + &#34;.jpg&#34;,
    )
    plt.savefig(outfile)

    print(&#34;Wrote &#34; + outfile)


# ============================================================
def main():
    parser = argparse.ArgumentParser()
    # parser.set_usage(&#39;python plot_overnight_data.py &lt;data directory&gt; &lt;start time as YYYYMMDD_HHMMSS or ctime&gt; &lt;stop time as YYYYMMDD_HHMMSS or ctime&gt; [options]&#39;)
    # parser.set_description(__doc__)
    parser.add_argument(&#34;data_dir&#34;, type=str, help=&#34;Direct data directory&#34;)
    parser.add_argument(
        &#34;time_start&#34;, type=str, help=&#34;Start time YYYYMMDD_HHMMSS or ctime. Both in UTC.&#34;
    )
    parser.add_argument(
        &#34;time_stop&#34;, type=str, help=&#34;Stop time YYYYMMDD_HHMMSS or ctime. Both in UTC.&#34;
    )
    parser.add_argument(
        &#34;-o&#34;,
        &#34;--outdir&#34;,
        dest=&#34;outdir&#34;,
        type=str,
        default=&#34;.&#34;,
        help=&#34;Output plot directory [default: .]&#34;,
    )

    parser.add_argument(
        &#34;-a&#34;,
        &#34;--avglen&#34;,
        dest=&#34;blocksize&#34;,
        default=10,
        type=int,
        help=&#34;number of chunks (rows) of direct spectra to average over. One chunk is roughly 6 seconds.&#34;,
    )
    parser.add_argument(
        &#34;-n&#34;,
        &#34;--acclen&#34;,
        dest=&#34;acclen&#34;,
        type=int,
        default=393216,
        help=&#34;Accumulation length to calculate accumulation time. Default 393216 ~ 6.44s&#34;,
    )
    parser.add_argument(
        &#34;-l&#34;,
        &#34;--logplot&#34;,
        dest=&#34;logplot&#34;,
        default=True,
        action=&#34;store_true&#34;,
        help=&#34;Plot in logscale&#34;,
    )
    parser.add_argument(
        &#34;-p&#34;,
        &#34;--plottype&#34;,
        dest=&#34;plottype&#34;,
        default=&#34;full&#34;,
        type=str,
        help=&#34;Type of plot to generate. &#39;full&#39;: pol00 and pol11 waterfall autospectra, min/max/mean/med autospectra, waterfall cross spectra. &#39;waterfall&#39;: same as 1, but no stats&#34;,
    )
    parser.add_argument(
        &#34;-tz&#34;,
        &#34;--timezone&#34;,
        type=str,
        default=&#34;US/Eastern&#34;,
        help=&#34;Valid timezone of the telescope recognized by pytz. E.g. US/Eastern. Default is US/Eastern.&#34;,
    )
    parser.add_argument(
        &#34;-vmi&#34;,
        &#34;--vmin&#34;,
        dest=&#34;vmin&#34;,
        default=None,
        type=float,
        help=&#34;minimum for colorbar. if nothing is specified, vmin is automatically set&#34;,
    )
    parser.add_argument(
        &#34;-vma&#34;,
        &#34;--vmax&#34;,
        dest=&#34;vmax&#34;,
        default=None,
        type=float,
        help=&#34;maximum for colorbar. if nothing is specified, vmax is automatically set&#34;,
    )
    parser.add_argument(
        &#34;-d&#34;,
        &#34;--datetimefmt&#34;,
        dest=&#34;datetimefmt&#34;,
        default=&#34;%m/%d %H:%M&#34;,
        type=str,
        help=&#34;Format for dates on axes of plots&#34;,
    )
    parser.add_argument(
        &#34;-fma&#34;,
        &#34;--fmax&#34;,
        dest=&#34;fmax&#34;,
        default=None,
        type=float,
        help=&#34;maximum for frequency to plot&#34;,
    )
    parser.add_argument(
        &#34;-fmi&#34;,
        &#34;--fmin&#34;,
        dest=&#34;fmin&#34;,
        default=None,
        type=float,
        help=&#34;minimum for frequency to plot&#34;,
    )
    parser.add_argument(
        &#34;-r&#34;,
        &#34;--rescale&#34;,
        dest=&#34;rescale&#34;,
        default=False,
        action=&#34;store_true&#34;,
        help=&#34;Rescale autospectra using median power&#34;,
    )
    parser.add_argument(
        &#34;-c&#34;, &#34;--common&#34;, action=&#34;store_true&#34;, help=&#34;Common colorbar for both pols&#34;
    )
    args = parser.parse_args()

    # =============== defining some global variables ===============#
    global freq, timezone, logplot, vmin, vmax, vmin2, vmax2, ctime_start, ctime_stop, blocksize, outdir, datetimefmt, rescale

    timezone = args.timezone
    vmin = args.vmin
    vmax = args.vmax
    logplot = args.logplot
    blocksize = args.blocksize
    outdir = args.outdir
    rescale = args.rescale
    mytz = pytz.timezone(args.timezone)
    datetimefmt = mdates.DateFormatter(
        args.datetimefmt, tz=mytz
    )  # formatter needs to be tz aware

    # =============================================================#

    # figuring out if human time or ctime was passed with pattern matching
    rx_human = re.compile(r&#34;^\d{8}_\d{6}$&#34;)
    rx_ctime = re.compile(r&#34;^\d{10}$&#34;)
    m1 = rx_human.search(args.time_start)
    m2 = rx_ctime.search(args.time_start)
    if m1:
        ctime_start = sft.timestamp2ctime(args.time_start)
        ctime_stop = sft.timestamp2ctime(args.time_stop)
    elif m2:
        ctime_start = int(args.time_start)
        ctime_stop = int(args.time_stop)
    else:
        raise ValueError(&#34;INVALID time format entered.&#34;)

    chunk_time = args.acclen * 4096 / 250e6

    # ================= reading data =================#
    pol00, pol11, pol01r, pol01i, tstart, tend = get_data_arrs(
        args.data_dir, ctime_start, ctime_stop, chunk_time, args.blocksize, mytz
    )
    # import sys
    # sys.exit(0)

    fmin, fmax = 0, 125
    if args.fmin:
        fmin = args.fmin
    if args.fmax:
        fmax = args.fmax

    cstart = int(np.floor(fmin / (250 / 4096)))
    cend = int(np.floor(fmax / (250 / 4096)))

    pol00 = pol00[:, cstart:cend]
    pol11 = pol11[:, cstart:cend]
    pol01r = pol01r[:, cstart:cend]
    pol01i = pol01i[:, cstart:cend]

    pol01 = pol01r + 1j * pol01i
    freq = np.arange(cstart, cend) * 250 / 4096  # 125 MHz is max frequency

    # ============ setting vmin and vmax ============#
    # setting vmin and vmax
    if vmin == None and vmax == None:
        vmin, vmax = get_vmin_vmax(pol00)
        vmin2, vmax2 = get_vmin_vmax(pol11)
        if logplot == True:
            vmin = np.log10(vmin)
            vmax = np.log10(vmax)
            vmin2 = np.log10(vmin2)
            vmax2 = np.log10(vmax2)
    if args.common:
        vmin = min(vmin, vmin2)
        vmax = max(vmax, vmax2)
        vmin2 = vmin
        vmax2 = vmax

    # ============ and finally: plotting! ============#
    if args.plottype == &#34;full&#34;:
        full_plot([pol00, pol11, pol01, tstart, tend], mytz, chunk_time)


if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="albatros_analysis.plot_overnight_new.full_plot"><code class="name flex">
<span>def <span class="ident">full_plot</span></span>(<span>data_arrs, mytz, chunk_time)</span>
</code></dt>
<dd>
<div class="desc"><p>Makes a plot that contains autospectra waterfalls for each pol, as well
as some statistics (min,max,med,mean spectra), and cross spectra</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def full_plot(data_arrs, mytz, chunk_time):
    &#34;&#34;&#34;
    Makes a plot that contains autospectra waterfalls for each pol, as well
    as some statistics (min,max,med,mean spectra), and cross spectra
    &#34;&#34;&#34;
    global vmin, vmax, vmin2, vmax2
    pol00, pol11, pol01, tstart, tend = data_arrs
    print(&#34;Generating stats for pol00&#34;)
    pol00_stats = get_stats(pol00)
    print(&#34;Generating stats for pol11&#34;)
    pol11_stats = get_stats(pol11)
    # print(&#34;WHERE POL11 ZERO&#34;, np.where(pol11==0))
    # print(&#34;Pol00 median&#34;, pol00_stats[&#39;median&#39;])
    if logplot is True:
        pol00 = np.log10(pol00)
        pol11 = np.log10(pol11)

    if rescale:
        scaling_pol00 = np.tile(pol00_stats[&#34;median&#34;], pol00.shape[0]).reshape(
            *pol00.shape
        )
        scaling_pol11 = np.tile(pol11_stats[&#34;median&#34;], pol11.shape[0]).reshape(
            *pol11.shape
        )
        pol00[:] = 10 * (
            pol00 - scaling_pol00
        )  # - instead of / for type 2 scaling: log(pol00/pol00_median)
        pol11[:] = 10 * (pol11 - scaling_pol11)
        vmin = -1
        vmax = 1
        vmin2 = vmin
        vmax2 = vmax

    y_extent = get_ylim_times(tstart, tend)
    ticks = np.linspace(y_extent[0], y_extent[1], 10)
    # print(y_extent)

    myext = np.array([freq[0], freq[-1], y_extent[1], y_extent[0]])

    plt.figure(figsize=(18, 10), dpi=200)
    plt.subplot(2, 3, 1)

    plt.imshow(pol00, vmin=vmin, vmax=vmax, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol00&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated log(power)&#34;, rotation=90)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.yticks(ticks)
    ax = plt.gca()
    ax.yaxis.set_major_formatter(datetimefmt)

    # this makes the code slow on Lab laptop.

    # nticks = 15 #desired number of ticks on the plot
    # hourinterval = int(pol00.shape[0]*chunk_time*blocksize/3600/nticks)
    # locator=mdates.HourLocator(interval=hourinterval,tz=mytz)
    # ax.yaxis.set_major_locator(locator)

    plt.subplot(2, 3, 4)
    plt.imshow(pol11, vmin=vmin2, vmax=vmax2, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol11&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated log(power)&#34;, rotation=90)
    plt.yticks(ticks)
    ax = plt.gca()
    ax.yaxis.set_major_formatter(datetimefmt)
    # ax.yaxis.set_major_locator(locator)

    plt.subplot(2, 3, 2)
    plt.title(&#34;Median power in frequency bins&#34;)
    plt.plot(freq, pol00_stats[&#34;max&#34;], &#34;r-&#34;, label=&#34;Max&#34;)
    plt.plot(freq, pol00_stats[&#34;min&#34;], &#34;b-&#34;, label=&#34;Min&#34;)
    plt.plot(freq, pol00_stats[&#34;mean&#34;], &#34;k-&#34;, label=&#34;Mean&#34;)
    plt.plot(
        freq, pol00_stats[&#34;median&#34;], color=&#34;#666666&#34;, linestyle=&#34;-&#34;, label=&#34;Median&#34;
    )
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.ylabel(&#34;pol00&#34;)
    plt.legend(loc=&#34;lower right&#34;, fontsize=&#34;small&#34;)
    plt.ylim(vmin, vmax)

    plt.subplot(2, 3, 5)
    plt.plot(freq, pol11_stats[&#34;max&#34;], &#34;r-&#34;, label=&#34;Max&#34;)
    plt.plot(freq, pol11_stats[&#34;min&#34;], &#34;b-&#34;, label=&#34;Min&#34;)
    plt.plot(freq, pol11_stats[&#34;mean&#34;], &#34;k-&#34;, label=&#34;Mean&#34;)
    plt.plot(
        freq, pol11_stats[&#34;median&#34;], color=&#34;#666666&#34;, linestyle=&#34;-&#34;, label=&#34;Median&#34;
    )
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    plt.ylabel(&#34;pol11&#34;)
    plt.ylim(vmin2, vmax2)

    plt.legend(loc=&#34;lower right&#34;, fontsize=&#34;small&#34;)

    plt.subplot(2, 3, 3)
    plt.imshow(np.log10(np.abs(pol01)), vmin=3, vmax=8, aspect=&#34;auto&#34;, extent=myext)
    plt.title(&#34;pol01 magnitude&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Uncalibrated power&#34;, rotation=90)
    plt.gca().set_yticklabels([])

    plt.subplot(2, 3, 6)
    plt.imshow(
        np.angle(pol01),
        vmin=-np.pi,
        vmax=np.pi,
        aspect=&#34;auto&#34;,
        extent=myext,
        cmap=&#34;RdBu&#34;,
    )
    plt.title(&#34;pol01 phase&#34;)
    plt.xlabel(&#34;Frequency (MHz)&#34;)
    cb00 = plt.colorbar()
    cb00.ax.set_ylabel(&#34;Radian&#34;, rotation=90)
    plt.gca().set_yticklabels([])

    range_localtime = list(
        map(partial(get_localtime_from_UTC, mytz=mytz), [tstart, tend])
    )
    print(&#34;start and end times are&#34;, tstart, tend)
    plt.suptitle(
        f&#39;Plotting {range_localtime[0].strftime(&#34;%b-%d %H:%M:%S&#34;)} to {range_localtime[1].strftime(&#34;%b-%d %H:%M:%S&#34;)} in {mytz.zone} \nAveraged over {blocksize} chunks ~ {blocksize*chunk_time/60:4.2f} minutes.&#39;
    )
    plt.tight_layout()
    outfile = os.path.join(
        outdir,
        &#34;direct_overnight_output&#34;
        + &#34;_&#34;
        + str(ctime_start)
        + &#34;_&#34;
        + str(ctime_stop)
        + &#34;.jpg&#34;,
    )
    plt.savefig(outfile)

    print(&#34;Wrote &#34; + outfile)</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_avg"><code class="name flex">
<span>def <span class="ident">get_avg</span></span>(<span>arr, block=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Fast average array over a given block size.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_avg(arr, block=10):
    &#34;&#34;&#34;
    Fast average array over a given block size.
    &#34;&#34;&#34;
    if arr is None:
        return None
    iters = arr.shape[0] // block
    leftover = arr.shape[0] % block
    # print(iters,leftover)
    nrows = iters + int(leftover &gt; 0)
    ncols = arr.shape[1]
    newarr = np.zeros((nrows, ncols), dtype=arr.dtype)
    cmp1 = np.median(arr[0, :]) / np.median(
        arr[1, :]
    )  # temporary fix, assuming only first row is expected to be faulty
    if cmp1 &gt; 1e2:
        # skip first row before averaging for first block
        newarr[0, :] = np.mean(arr[1:block, :], axis=0)
        newarr[1:iters, :] = np.mean(
            arr[block : iters * block, :].reshape(-1, block, ncols), axis=1
        )
    else:
        # print(f&#34;Shape of passed arr {arr.shape} and shape of new arr {newarr.shape}&#34;)
        newarr[:iters, :] = np.mean(
            arr[: iters * block, :].reshape(-1, block, ncols), axis=1
        )
    if leftover:
        newarr[iters, :] = np.mean(arr[iters * block :, :], axis=0)
    return newarr</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_data_arrs"><code class="name flex">
<span>def <span class="ident">get_data_arrs</span></span>(<span>data_dir: str, ctime_start: str, ctime_stop: str, chunk_time, blocklen, mytz)</span>
</code></dt>
<dd>
<div class="desc"><p>Given the path to a Big data directory (i.e. directory contains the directories
labeled by the first 5 digits of the ctime date), gets all the data in some time interval.</p>
<h2 id="parameters">Parameters:</h2>
<p>data_dir: str
path to data directory</p>
<p>ctime_start, ctime_stop: str
desired start and stop time in ctime</p>
<p>chunk_time: ??</p>
<p>blocklen: (probably int)</p>
<p>mytz: (what kind of object is this? probably pytz.tzfile)
Timezone (of the dish at collection?)</p>
<h2 id="returns">Returns:</h2>
<p>cimte_start, ctime_stop: int
start and stop times in ctime</p>
<p>pol00,pol11,pol01r,pol01i: array
2D arrays containing the data for given time interval for autospectra
as well as cross spectra. pol00 corresponds to adc0 and pol11 to adc3</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data_arrs(data_dir: str, ctime_start: str, ctime_stop: str, chunk_time, blocklen, mytz):
    &#34;&#34;&#34;
    Given the path to a Big data directory (i.e. directory contains the directories
    labeled by the first 5 digits of the ctime date), gets all the data in some time interval.

    Parameters:
    -----------

    data_dir: str
        path to data directory

    ctime_start, ctime_stop: str
        desired start and stop time in ctime

    chunk_time: ??
    
    blocklen: (probably int)
    
    mytz: (what kind of object is this? probably pytz.tzfile)
        Timezone (of the dish at collection?)

    Returns:
    --------

    cimte_start, ctime_stop: int
        start and stop times in ctime

    pol00,pol11,pol01r,pol01i: array
        2D arrays containing the data for given time interval for autospectra
        as well as cross spectra. pol00 corresponds to adc0 and pol11 to adc3
    &#34;&#34;&#34;
    print(&#34;\n################### READING DATA ###################&#34;)
    print(f&#34;Files requested between timestamps {ctime_start} to {ctime_stop}&#34;)
    print(
        f&#34;Corresponding UTC time: {datetime.utcfromtimestamp(ctime_start)} to {datetime.utcfromtimestamp(ctime_stop)}&#34;
    )

    # all the dirs between the timestamps. read all, append, average over chunk length
    data_subdirs = sft.time2fnames(ctime_start, ctime_stop, data_dir)
    print(&#34;total data subdirs&#34;, len(data_subdirs))
    print(&#34;First and last subdirs:&#34;, data_subdirs[0], data_subdirs[-1])
    data_subdirs.sort()

    if len(data_subdirs) == 0:
        print(&#34;NOTHING WAS READ. CHECK TSTAMPS&#34;)
        sys.exit(1)

    # rough estimate of number of rows we&#39;ll read
    nrows_guess = len(data_subdirs) * ((int(3600 / chunk_time / blocklen) + 1) + 1)
    # print(&#34;Starting with a guess of &#34;, nrows_guess)
    print(&#34;guessed rows&#34;, nrows_guess)
    pol00 = np.zeros((nrows_guess + 500, 2048))

    nrows = 0

    t1 = time.time()
    new_dirs = [d + &#34;/pol00.scio.bz2&#34; for d in data_subdirs]
    datpol00 = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol11.scio.bz2&#34; for d in data_subdirs]
    datpol11 = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol01r.scio.bz2&#34; for d in data_subdirs]
    datpol01r = scio.read_files(new_dirs)
    new_dirs = [d + &#34;/pol01i.scio.bz2&#34; for d in data_subdirs]
    datpol01i = scio.read_files(new_dirs)
    print(time.time() - t1, f&#34;Read {len(data_subdirs)} files&#34;)

    # average everything if blocklen&gt;1
    # print(&#34;first row must be in:&#34;, data_subdirs[0])

    myavgfunc = partial(get_avg, block=blocklen)
    if blocklen &gt; 1:
        t1 = time.time()
        with Pool(os.cpu_count()) as p:
            avgpol00 = p.map(myavgfunc, datpol00)
            avgpol11 = p.map(myavgfunc, datpol11)
            avgpol01r = p.map(myavgfunc, datpol01r)
            avgpol01i = p.map(myavgfunc, datpol01i)
        print(time.time() - t1, &#34;averaged everything&#34;)
    else:
        avgpol00 = datpol00
        avgpol11 = datpol11
        avgpol01r = datpol01r
        avgpol01i = datpol01i

    print(len(avgpol00))
    t1 = time.time()
    tstart = 0
    tend = 0
    for i, d in enumerate(avgpol00):
        # print(&#34;Mean, median are&#34;, np.mean(d,axis=0),np.median(d,axis=0))
        print(&#34;working on&#34;, data_subdirs[i])
        if d is None:
            continue
        if i == 0:
            pol00[: d.shape[0]] = d
            nrows += d.shape[0]
            ts = get_ts_from_name(data_subdirs[i])

            tstart = ts  # save starting time for user output
            ts = ts + d.shape[0] * chunk_time * blocklen
            continue
        newts = get_ts_from_name(data_subdirs[i])
        diff = int((newts - ts) / chunk_time / blocklen)
        # each cell in the plot represents a minimum time of blocklen * chunktime.
        # That&#39;s the time resolution for the plot. Can&#39;t catch gaps &lt; resolution.
        if diff &gt; 0:
            print(f&#34;significant diff b/w files {tstart} and {newts} of:&#34;, diff, &#34;rows&#34;)
            pol00[nrows : nrows + diff, :] = np.nan
            pol00 = np.append(pol00, np.zeros((diff, 2048)), axis=0)
            nrows += diff
        # print(nrows, d.shape)
        # print(nrows,nrows+d.shape[0],pol00.shape,&#34;heh&#34;)
        pol00[nrows : nrows + d.shape[0], :] = d
        nrows += d.shape[0]
        # print(&#34;reading&#34;, data_subdirs[i], &#34;with size &#34;, d.shape[0], &#34;NROWS&#34;, oldnrows,nrows)
        tstart = newts
        ts = newts + d.shape[0] * chunk_time * blocklen
    tend = ts
    # print(&#34;HERE&#34;)
    # once we have pol00, we know the exact size. use it
    tstart = get_ts_from_name(
        data_subdirs[0]
    )  # tstart was replaced above for missing gap info
    print(&#34;############################################################&#34;)
    print(
        f&#34;First file at: {tstart}, Last file at: {get_ts_from_name(data_subdirs[-1])}&#34;
    )
    print(f&#34;Plotting all data starting {tstart} and ending {int(tend)}&#34;)
    ts, te = list(map(partial(get_localtime_from_UTC, mytz=mytz), [tstart, tend]))
    print(
        f&#34;In Local time: {ts.strftime(&#39;%b-%d %H:%M:%S&#39;)} to {te.strftime(&#39;%b-%d %H:%M:%S&#39;)} in {mytz.zone}&#34;
    )
    print(&#34;Final nrows:&#34;, nrows)

    pol00 = pol00[:nrows].copy()
    # print(pol00.shape)

    pol11 = np.zeros((nrows, 2048))
    pol01r = np.zeros((nrows, 2048))
    pol01i = np.zeros((nrows, 2048))

    nrows = 0
    for i in range(len(avgpol00)):
        if (avgpol11[i] is None) or (avgpol01i[i] is None) or (avgpol01r[i] is None):
            continue
        if i == 0:
            r = avgpol11[i].shape[0]
            pol11[:r, :] = avgpol11[i]
            pol01r[:r, :] = avgpol01r[i]
            pol01i[:r, :] = avgpol01i[i]
            nrows += r
            ts = get_ts_from_name(data_subdirs[i]) + r * chunk_time * blocklen
            continue
        newts = get_ts_from_name(data_subdirs[i])
        diff = int((newts - ts) / chunk_time / blocklen)
        if diff &gt; 0:
            pol11[nrows : nrows + diff, :] = np.nan
            pol01r[nrows : nrows + diff, :] = np.nan
            pol01i[nrows : nrows + diff, :] = np.nan
            nrows += diff
        r = avgpol11[i].shape[0]
        pol11[nrows : nrows + r, :] = avgpol11[i]
        pol01r[nrows : nrows + r, :] = avgpol01r[i]
        pol01i[nrows : nrows + r, :] = avgpol01i[i]
        nrows += r
        ts = newts + r * chunk_time * blocklen

    t2 = time.time()
    # print(&#39;Time taken to concatenate data:&#39;,t2-t1)
    # print(&#34;pol00, pol11,pol01r, pol01i shape:&#34;, pol00.shape,pol11.shape,pol01r.shape,pol01i.shape)
    pol00 = np.ma.masked_invalid(pol00)
    pol11 = np.ma.masked_invalid(pol11)
    pol01r = np.ma.masked_invalid(pol01r)
    pol01i = np.ma.masked_invalid(pol01i)
    return pol00, pol11, pol01r, pol01i, tstart, tend</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_localtime_from_UTC"><code class="name flex">
<span>def <span class="ident">get_localtime_from_UTC</span></span>(<span>tstamp, mytz)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_localtime_from_UTC(tstamp, mytz):
    return datetime.fromtimestamp(int(tstamp), tz=pytz.utc).astimezone(tz=mytz)</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_stats"><code class="name flex">
<span>def <span class="ident">get_stats</span></span>(<span>data_arr)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a 2D array containing some data chunk, returns the
min, median, mean, and max over that chunk.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_stats(data_arr):
    &#34;&#34;&#34;
    Given a 2D array containing some data chunk, returns the
    min, median, mean, and max over that chunk.
    &#34;&#34;&#34;
    # print(&#34;WHERE MIN ZERO&#34;,np.where(np.min(data_arr,axis=0)==0))
    # print(&#34;WHERE MEDIAN ZERO&#34;,np.where(np.median(data_arr,axis=0)==0))
    # print(&#34;MEDIAN&#34;,np.median(data_arr,axis=0))
    # print(&#34;MEDIAN MA&#34;,np.ma.median(data_arr,axis=0))
    if logplot:
        stats = {
            &#34;min&#34;: np.log10(np.ma.min(data_arr, axis=0)),
            &#34;median&#34;: np.log10(np.ma.median(data_arr, axis=0)),
            &#34;mean&#34;: np.log10(np.ma.mean(data_arr, axis=0)),
            &#34;max&#34;: np.log10(np.ma.max(data_arr, axis=0)),
        }
    else:
        stats = {
            &#34;min&#34;: np.ma.min(data_arr, axis=0),
            &#34;median&#34;: np.ma.median(data_arr, axis=0),
            &#34;mean&#34;: np.ma.mean(data_arr, axis=0),
            &#34;max&#34;: np.ma.max(data_arr, axis=0),
        }
    return stats</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_ts_from_name"><code class="name flex">
<span>def <span class="ident">get_ts_from_name</span></span>(<span>f)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_ts_from_name(f):
    return int(f.split(&#34;/&#34;)[-1])</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_vmin_vmax"><code class="name flex">
<span>def <span class="ident">get_vmin_vmax</span></span>(<span>data_arr)</span>
</code></dt>
<dd>
<div class="desc"><p>Automatically gets vmin and vmax for colorbar</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_vmin_vmax(data_arr):
    &#34;&#34;&#34;
    Automatically gets vmin and vmax for colorbar
    &#34;&#34;&#34;
    # print(&#34;shape of passed array&#34;, data_arr.shape, data_arr.dtype)
    xx = data_arr[~data_arr.mask].data
    med = np.percentile(xx, 50)
    # print(med, &#34;median&#34;)
    u = np.percentile(xx, 99)
    b = np.percentile(xx, 1)
    xx_clean = xx[(xx &lt;= u) &amp; (xx &gt;= b)]  # remove some outliers for better plotting
    stddev = np.std(xx_clean)
    vmin = max(med - 2 * stddev, 10**7)
    vmax = med + 2 * stddev
    # print(&#34;vmin, vmax are&#34;, vmin, vmax)
    return vmin, vmax</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.get_ylim_times"><code class="name flex">
<span>def <span class="ident">get_ylim_times</span></span>(<span>t_i, t_f)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the y limits in matplotlib's date format for a given initial time
and final time. t_i and t_f must be given in ctime</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_ylim_times(t_i, t_f):
    &#34;&#34;&#34;
    Gets the y limits in matplotlib&#39;s date format for a given initial time
    and final time. t_i and t_f must be given in ctime
    &#34;&#34;&#34;
    # getlocaltime = lambda tstamp: datetime.fromtimestamp(int(tstamp),tz=pytz.utc).astimezone(tz=mytz)
    y_lims = list(map(datetime.utcfromtimestamp, [t_i, t_f]))
    y_lims_plt = mdates.date2num(y_lims)
    # date2num is NOT tz aware.
    # will return same value regardless of tz of passed datetime object.
    # pass tz to formatter and tick locators
    return y_lims_plt</code></pre>
</details>
</dd>
<dt id="albatros_analysis.plot_overnight_new.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    parser = argparse.ArgumentParser()
    # parser.set_usage(&#39;python plot_overnight_data.py &lt;data directory&gt; &lt;start time as YYYYMMDD_HHMMSS or ctime&gt; &lt;stop time as YYYYMMDD_HHMMSS or ctime&gt; [options]&#39;)
    # parser.set_description(__doc__)
    parser.add_argument(&#34;data_dir&#34;, type=str, help=&#34;Direct data directory&#34;)
    parser.add_argument(
        &#34;time_start&#34;, type=str, help=&#34;Start time YYYYMMDD_HHMMSS or ctime. Both in UTC.&#34;
    )
    parser.add_argument(
        &#34;time_stop&#34;, type=str, help=&#34;Stop time YYYYMMDD_HHMMSS or ctime. Both in UTC.&#34;
    )
    parser.add_argument(
        &#34;-o&#34;,
        &#34;--outdir&#34;,
        dest=&#34;outdir&#34;,
        type=str,
        default=&#34;.&#34;,
        help=&#34;Output plot directory [default: .]&#34;,
    )

    parser.add_argument(
        &#34;-a&#34;,
        &#34;--avglen&#34;,
        dest=&#34;blocksize&#34;,
        default=10,
        type=int,
        help=&#34;number of chunks (rows) of direct spectra to average over. One chunk is roughly 6 seconds.&#34;,
    )
    parser.add_argument(
        &#34;-n&#34;,
        &#34;--acclen&#34;,
        dest=&#34;acclen&#34;,
        type=int,
        default=393216,
        help=&#34;Accumulation length to calculate accumulation time. Default 393216 ~ 6.44s&#34;,
    )
    parser.add_argument(
        &#34;-l&#34;,
        &#34;--logplot&#34;,
        dest=&#34;logplot&#34;,
        default=True,
        action=&#34;store_true&#34;,
        help=&#34;Plot in logscale&#34;,
    )
    parser.add_argument(
        &#34;-p&#34;,
        &#34;--plottype&#34;,
        dest=&#34;plottype&#34;,
        default=&#34;full&#34;,
        type=str,
        help=&#34;Type of plot to generate. &#39;full&#39;: pol00 and pol11 waterfall autospectra, min/max/mean/med autospectra, waterfall cross spectra. &#39;waterfall&#39;: same as 1, but no stats&#34;,
    )
    parser.add_argument(
        &#34;-tz&#34;,
        &#34;--timezone&#34;,
        type=str,
        default=&#34;US/Eastern&#34;,
        help=&#34;Valid timezone of the telescope recognized by pytz. E.g. US/Eastern. Default is US/Eastern.&#34;,
    )
    parser.add_argument(
        &#34;-vmi&#34;,
        &#34;--vmin&#34;,
        dest=&#34;vmin&#34;,
        default=None,
        type=float,
        help=&#34;minimum for colorbar. if nothing is specified, vmin is automatically set&#34;,
    )
    parser.add_argument(
        &#34;-vma&#34;,
        &#34;--vmax&#34;,
        dest=&#34;vmax&#34;,
        default=None,
        type=float,
        help=&#34;maximum for colorbar. if nothing is specified, vmax is automatically set&#34;,
    )
    parser.add_argument(
        &#34;-d&#34;,
        &#34;--datetimefmt&#34;,
        dest=&#34;datetimefmt&#34;,
        default=&#34;%m/%d %H:%M&#34;,
        type=str,
        help=&#34;Format for dates on axes of plots&#34;,
    )
    parser.add_argument(
        &#34;-fma&#34;,
        &#34;--fmax&#34;,
        dest=&#34;fmax&#34;,
        default=None,
        type=float,
        help=&#34;maximum for frequency to plot&#34;,
    )
    parser.add_argument(
        &#34;-fmi&#34;,
        &#34;--fmin&#34;,
        dest=&#34;fmin&#34;,
        default=None,
        type=float,
        help=&#34;minimum for frequency to plot&#34;,
    )
    parser.add_argument(
        &#34;-r&#34;,
        &#34;--rescale&#34;,
        dest=&#34;rescale&#34;,
        default=False,
        action=&#34;store_true&#34;,
        help=&#34;Rescale autospectra using median power&#34;,
    )
    parser.add_argument(
        &#34;-c&#34;, &#34;--common&#34;, action=&#34;store_true&#34;, help=&#34;Common colorbar for both pols&#34;
    )
    args = parser.parse_args()

    # =============== defining some global variables ===============#
    global freq, timezone, logplot, vmin, vmax, vmin2, vmax2, ctime_start, ctime_stop, blocksize, outdir, datetimefmt, rescale

    timezone = args.timezone
    vmin = args.vmin
    vmax = args.vmax
    logplot = args.logplot
    blocksize = args.blocksize
    outdir = args.outdir
    rescale = args.rescale
    mytz = pytz.timezone(args.timezone)
    datetimefmt = mdates.DateFormatter(
        args.datetimefmt, tz=mytz
    )  # formatter needs to be tz aware

    # =============================================================#

    # figuring out if human time or ctime was passed with pattern matching
    rx_human = re.compile(r&#34;^\d{8}_\d{6}$&#34;)
    rx_ctime = re.compile(r&#34;^\d{10}$&#34;)
    m1 = rx_human.search(args.time_start)
    m2 = rx_ctime.search(args.time_start)
    if m1:
        ctime_start = sft.timestamp2ctime(args.time_start)
        ctime_stop = sft.timestamp2ctime(args.time_stop)
    elif m2:
        ctime_start = int(args.time_start)
        ctime_stop = int(args.time_stop)
    else:
        raise ValueError(&#34;INVALID time format entered.&#34;)

    chunk_time = args.acclen * 4096 / 250e6

    # ================= reading data =================#
    pol00, pol11, pol01r, pol01i, tstart, tend = get_data_arrs(
        args.data_dir, ctime_start, ctime_stop, chunk_time, args.blocksize, mytz
    )
    # import sys
    # sys.exit(0)

    fmin, fmax = 0, 125
    if args.fmin:
        fmin = args.fmin
    if args.fmax:
        fmax = args.fmax

    cstart = int(np.floor(fmin / (250 / 4096)))
    cend = int(np.floor(fmax / (250 / 4096)))

    pol00 = pol00[:, cstart:cend]
    pol11 = pol11[:, cstart:cend]
    pol01r = pol01r[:, cstart:cend]
    pol01i = pol01i[:, cstart:cend]

    pol01 = pol01r + 1j * pol01i
    freq = np.arange(cstart, cend) * 250 / 4096  # 125 MHz is max frequency

    # ============ setting vmin and vmax ============#
    # setting vmin and vmax
    if vmin == None and vmax == None:
        vmin, vmax = get_vmin_vmax(pol00)
        vmin2, vmax2 = get_vmin_vmax(pol11)
        if logplot == True:
            vmin = np.log10(vmin)
            vmax = np.log10(vmax)
            vmin2 = np.log10(vmin2)
            vmax2 = np.log10(vmax2)
    if args.common:
        vmin = min(vmin, vmin2)
        vmax = max(vmax, vmax2)
        vmin2 = vmin
        vmax2 = vmax

    # ============ and finally: plotting! ============#
    if args.plottype == &#34;full&#34;:
        full_plot([pol00, pol11, pol01, tstart, tend], mytz, chunk_time)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="albatros_analysis" href="index.html">albatros_analysis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="albatros_analysis.plot_overnight_new.full_plot" href="#albatros_analysis.plot_overnight_new.full_plot">full_plot</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_avg" href="#albatros_analysis.plot_overnight_new.get_avg">get_avg</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_data_arrs" href="#albatros_analysis.plot_overnight_new.get_data_arrs">get_data_arrs</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_localtime_from_UTC" href="#albatros_analysis.plot_overnight_new.get_localtime_from_UTC">get_localtime_from_UTC</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_stats" href="#albatros_analysis.plot_overnight_new.get_stats">get_stats</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_ts_from_name" href="#albatros_analysis.plot_overnight_new.get_ts_from_name">get_ts_from_name</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_vmin_vmax" href="#albatros_analysis.plot_overnight_new.get_vmin_vmax">get_vmin_vmax</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.get_ylim_times" href="#albatros_analysis.plot_overnight_new.get_ylim_times">get_ylim_times</a></code></li>
<li><code><a title="albatros_analysis.plot_overnight_new.main" href="#albatros_analysis.plot_overnight_new.main">main</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>