<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>albatros_analysis.SNAPfiletools API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>albatros_analysis.SNAPfiletools</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import time, datetime, os, re
import numpy as np
from scio import scio


def read_field_many_fast(dirs,tag,dtype=&#39;float64&#39;,return_missing=False):
    &#34;&#34;&#34;Reads one baseline from multiple data dumps. 
    
    *Warning* Do both this function and read_pol_fast have different use 
    cases? The only difference I can see is that this one also has option 
    to return missing files, and is implemented slightly differently 
    (does not use scio [pbio]). 
    
    Parameters
    ----------
    dirs: list
        List of paths to baseline data files. 
    tag: str
        Identifies which polarization baseline. E.g. &#39;pol00&#39;
    dtype: str
        Specifies numpy primitive data-type. 
    return_missing: bool
        If True, returns list of paths where data is missing as second 
        return parameter. Defaults to False. 
    
    
    Returns
    -------
    np.ndarray or tuple[np.ndarray, list]
        A numpy array containing all xcorr/autocorr baseline data 
        requested. If none was found, returns None. If return_missing 
        is True, returns a list of filepaths that point to non-existant
        data. 
    &#34;&#34;&#34;
    ndir=len(dirs)
    all_dat=[None]*ndir
    missing=[]
    ndat=0
    for i in range(ndir):
        try:
            fname=dirs[i]+&#39;/&#39;+tag # todo: change to os.path.join(dirs[i], tag)
            all_dat[i]=np.fromfile(fname,dtype=dtype)
            ndat=ndat+len(all_dat[i])
        except:
            missing.append(fname)
    if ndat&gt;0:
        dat=np.zeros(ndat,dtype=dtype)
        ii=0
        for i in range(ndir):
            if not(all_dat[i] is None):
                nn=len(all_dat[i])
                if nn&gt;0:
                    dat[ii:ii+nn]=all_dat[i]
                    ii+=nn
        if return_missing:
            return dat,missing
        else:
            return dat
    else:
        if return_missing:
            return None,missing
        else:
            return None
    

def read_pol_fast(dirs,tag):
    &#34;&#34;&#34;Reads one baseline from multiple data dumps.
    
    A baseline is identified by tag, the data is identified by dirs. 
    Relevant data are read and returned as a 2d numpy array. 
    
    Parameters
    ----------
    dirs: list of str
        List of paths to baseline data files. 
    tag: str
        Identifies which polarization baseline. E.g. &#39;pol00&#39;
        
    Returns
    -------
    big_dat: np.ndarray with shape (ndat, nchan)
        A 2-d numpy array that stores all relevant data. 
    &#34;&#34;&#34;
    ndir=len(dirs)
    fnames=[None]*ndir
    for i in range(ndir):
        fnames[i]=dirs[i]+&#39;/&#39;+tag 
    # Once we have tests, above 4 lines can be condensed into: 
    # fnames = [os.path.join(d,tag) for d in dirs]
    t0=time.time()
    all_dat=scio.read_files(fnames) # all data files
    t1=time.time()
    print(&#39;read files in &#39;,t1-t0)
    ndat=0
    for dat in all_dat:
        if not(dat is None): # if dat is not None
            ndat=ndat+dat.shape[0]
            nchan=dat.shape[1]

    if ndat&gt;0:
        big_dat=np.zeros([ndat,nchan])
        ii=0
        for dat in all_dat:
            if not(dat is None):
                nn=dat.shape[0]
                big_dat[ii:(ii+nn),:]=dat
                ii=ii+nn
    else:
        print(&#39;No files found in read_pol_fast.&#39;)
        big_dat=None
    return big_dat
    

def ctime2timestamp(ctimes):
    &#34;&#34;&#34;Given a (list of) ctime, convert to human friendly format.

    Parameters
    ----------
    ctime: int or float or list of int/float
        (List of) ctime(s).

    Returns 
    -------
    list
        The time stamps (or list of time stamps) in human friendly format.
    &#34;&#34;&#34;

    if isinstance(ctimes, (int, float)):
        return str(datetime.datetime.utcfromtimestamp(ctimes))
    else:
        return [ str(datetime.datetime.utcfromtimestamp(c)) for c in ctimes ]


def timestamp2ctime(date_strings, time_format=&#39;%Y%m%d_%H%M%S&#39;):
    &#34;&#34;&#34;Converts list of date strings into ctime format.
    
    Given a string time stamp (or list of time stamps) in human-frendly
    format, with default being YYYYMMSS_HHMMSS, convert to datetime
    object and calculate ctime.

    Parameters
    ----------
    date_strings: str or list of str
        Time stamp(s) in desired text format
    time_format: str or list of str
        Formatting string for datetime

    Returns
    -------
    list 
        The time stamps (or list of time stamps) in ctime.
     &#34;&#34;&#34;

    t0 = datetime.datetime(1970, 1, 1)

    if isinstance(date_strings, str):
        return int((datetime.datetime.strptime(date_strings, time_format) - t0).total_seconds())
    else:
        return [ int((datetime.datetime.strptime(d, time_format) - t0).total_seconds()) for d in date_strings ]


def time2fnames(time_start, time_stop, dir_parent, fraglen=5):
    &#34;&#34;&#34;Gets a list of filenames within specified time-rage. 
    
    Given a start and stop ctime, retrieve list of corresponding files.
    This function assumes that the parent directory has the directory
    structure &lt;dir_parent&gt;/&lt;5-digit coarse time fragment&gt;/&lt;10-digit
    fine time stamp&gt;.

    Paramaters:
    -----------
    time_start, time_stop: int 
        start/stop times in ctime 
    
    dir_parent: str
        parent directory, e.g. /path/to/data_100MHz
    
    fraglen: int 
        number of digits in coarse time fragments
    
    Returns 
    -------
    list of str
        List of files in specified time range.
    &#34;&#34;&#34;

    times_coarse = os.listdir(dir_parent)
    times_coarse.sort()
    s = re.compile(r&#39;(\d{10})&#39;)  # We&#39;ll use this to search for 10-digit time strings
    fnames = []
    for time_coarse in times_coarse:
        try:
            # Include +-1 coarse directory on endpoints because
            # sometimes the fine time stamp rolls over to the coarse
            # time within the same directory
            if ((int(time_coarse) &lt; int(str(time_start)[:fraglen])-1) or (int(time_coarse) &gt; int(str(time_stop)[:fraglen])+1)):
                continue 
            
            all_fnames = os.listdir(&#39;{}/{}&#39;.format(dir_parent, time_coarse))
            all_fnames.sort()

            for f in all_fnames:
                if s.search(f):
                    tstamp = int(s.search(f).groups()[0])
                    if tstamp &gt;= time_start and tstamp &lt;= time_stop:
                        # fnames.append(dir_parent+&#39;/&#39;+time_coarse+&#39;/&#39;+f)
                        fnames.append(os.path.join(dir_parent,time_coarse,f))
        except:
            pass
    fnames.sort()
    return fnames


  
def ctime2data(dir_parent, ct_start, ct_stop, pols = [0,1], time_file=&#39;time_gps_start.raw&#39;, fraglen=5):
    &#34;&#34;&#34;Given a parent directory containing all SNAP data (eg. data_auto_cross), 
    and start and stop timestamp in human-friendly format (default being
    YYYYMMDD_HHMMSS), returns all the data between those times.

    - parentdir = dirctory conatining all SNAP data (string)
    - ct_start(/stop) = start(/stop) timestamps in UNIX time
    - pols = array of polarizations to read
    - time_file = name of file with time stamp data
    
    Returns array of 2d arrays, arranged by polarization:
    auto, ..., cross_r, cross_i, ...
    &#34;&#34;&#34;

    fnames = time2fnames(ct_start, ct_stop, dir_parent, fraglen=fraglen)

    time = read_field_many_fast(fnames, time_file)

    inds = np.where( (time &gt;= ct_start) &amp; (time &lt;= ct_stop) )[0]
    time = time[inds]
    
    print(&#34;Requested start time was: &#34;+str(ct_start))
    print(&#34;Requested stop time was: &#34;+str(ct_stop))
    print(&#34;Actual start time is: &#34;+str(time[0]))
    print(&#34;Actual stop time is: &#34;+str(time[-1]))
        
    data = []
    for pol in pols:
        tag = &#39;pol{0}{0}.scio&#39;.format(pol)
        poldata = read_pol_fast(fnames, tag)
        data.append(poldata)

    for i in xrange(len(pols)):
        for j in xrange(i+1, len(pols)):
            for reality in [&#39;r&#39;, &#39;i&#39;]:
                tag = &#39;pol{}{}{}.scio&#39;.format(i,j,reality)
                poldata = read_pol_fast(fnames, tag)
                data.append(poldata)

    data = np.asarray(data)
    data = data[:,inds]

    return time, data



def callocdir(dir_name):
    &#34;&#34;&#34;Allocate and initialize a directory. (think calloc/malloc in C)
    
    Make sure a directory specified exists and is empty. If it doesn&#39;t
    exist, create it; if it&#39;s not empty, empty it.
    
    Parameters
    ----------
    dir_name: str
        The path to the directory we want to allocate. 
    &#34;&#34;&#34;
    if os.path.exists(dir_name) == False: # == False -&gt; is False
        os.mkdir(dir_name)
    else: #empty it before writing into it (who knows wtf is in it)
        for  file_name in os.listdir(dir_name):
            temp_path = os.path.join(dir_name, file_name)
            try:
                os.unlink(temp_path)
            except Exception as error:
                print(&#34;failed to delete: &#34; + str(temp_path) + &#34; cause: &#34; + str(error))
                return
    return

def mallocdir(dir_name):
    &#34;&#34;&#34;Allocate a directory without initializing it. (think calloc/malloc)
    
    If a directory doesn&#39;t exist, create it; otherwise, leave it as it is. 
    
    Parameters
    ----------
    dir_name: str
        The path to the directory we want to allocate. 
    &#34;&#34;&#34;
    if os.path.exists(dir_name) == False:
        os.mkdir(dir_name)
    return

def readin_computed(fname):
    &#34;&#34;&#34;Read binary file into numpy array. 
    
    *Warning*, this may be depricated (with 
    functionality contained within `read_pol_fast` subroutine)
    
    Thin wrapper for np.load().
    
    Parameters
    ----------
    fname: str
        Path to binary file. 

    Returns
    -------
    np.ndarray
        The binary array at fname. 
    &#34;&#34;&#34;
    with open(fname, &#39;rb&#39;) as f:
        out = np.load(f)
    return out


def readin_append(dir_names, base_file_path, file_name, function):
    &#34;&#34;&#34;Read multiple files fast. 
    
    *Warning* This may be a duplicate of `read_field_many_fast`. 
    
    Looks through multiple specified sub-directories of base_file_path 
    for leaves (files) with one specific name. Applies function to each
    file. E.g. This method can be used to load multiple data from one 
    multiple files containing the same baseline (xcorr/autocorr) into 
    an array.
    
    Parameters
    ----------
    dir_names: list of str
        List of relative directory names. 
    base_file_path: str
        Path to the base file in which we search for sub-directories 
        &#39;dir_names&#39;. 
    file_name: str
        Name of the leaf node (file). A similar variable is refered to as 
        &#39;tag&#39; above. 
    function: callable
        Applied to filepath. Takes path-string and returns numpy array. 
    
    Returns
    -------
    data: np.ndarray
        Most likely this will be used to read 
    &#34;&#34;&#34;
    for index, dir_name in enumerate(dir_names):
        file_path = os.path.join(base_file_path, dir_name, file_name)
        if index ==0:
            data = function(file_path)
        else:
            data = np.append(data,function(file_path), axis = 0)
            # print(&#34;append so shape is now&#34;)
            # print(np.shape(data))
    # print(np.shape(data))
    return data </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="albatros_analysis.SNAPfiletools.callocdir"><code class="name flex">
<span>def <span class="ident">callocdir</span></span>(<span>dir_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Allocate and initialize a directory. (think calloc/malloc in C)</p>
<p>Make sure a directory specified exists and is empty. If it doesn't
exist, create it; if it's not empty, empty it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dir_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory we want to allocate.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def callocdir(dir_name):
    &#34;&#34;&#34;Allocate and initialize a directory. (think calloc/malloc in C)
    
    Make sure a directory specified exists and is empty. If it doesn&#39;t
    exist, create it; if it&#39;s not empty, empty it.
    
    Parameters
    ----------
    dir_name: str
        The path to the directory we want to allocate. 
    &#34;&#34;&#34;
    if os.path.exists(dir_name) == False: # == False -&gt; is False
        os.mkdir(dir_name)
    else: #empty it before writing into it (who knows wtf is in it)
        for  file_name in os.listdir(dir_name):
            temp_path = os.path.join(dir_name, file_name)
            try:
                os.unlink(temp_path)
            except Exception as error:
                print(&#34;failed to delete: &#34; + str(temp_path) + &#34; cause: &#34; + str(error))
                return
    return</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.ctime2data"><code class="name flex">
<span>def <span class="ident">ctime2data</span></span>(<span>dir_parent, ct_start, ct_stop, pols=[0, 1], time_file='time_gps_start.raw', fraglen=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a parent directory containing all SNAP data (eg. data_auto_cross),
and start and stop timestamp in human-friendly format (default being
YYYYMMDD_HHMMSS), returns all the data between those times.</p>
<ul>
<li>parentdir = dirctory conatining all SNAP data (string)</li>
<li>ct_start(/stop) = start(/stop) timestamps in UNIX time</li>
<li>pols = array of polarizations to read</li>
<li>time_file = name of file with time stamp data</li>
</ul>
<p>Returns array of 2d arrays, arranged by polarization:
auto, &hellip;, cross_r, cross_i, &hellip;</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ctime2data(dir_parent, ct_start, ct_stop, pols = [0,1], time_file=&#39;time_gps_start.raw&#39;, fraglen=5):
    &#34;&#34;&#34;Given a parent directory containing all SNAP data (eg. data_auto_cross), 
    and start and stop timestamp in human-friendly format (default being
    YYYYMMDD_HHMMSS), returns all the data between those times.

    - parentdir = dirctory conatining all SNAP data (string)
    - ct_start(/stop) = start(/stop) timestamps in UNIX time
    - pols = array of polarizations to read
    - time_file = name of file with time stamp data
    
    Returns array of 2d arrays, arranged by polarization:
    auto, ..., cross_r, cross_i, ...
    &#34;&#34;&#34;

    fnames = time2fnames(ct_start, ct_stop, dir_parent, fraglen=fraglen)

    time = read_field_many_fast(fnames, time_file)

    inds = np.where( (time &gt;= ct_start) &amp; (time &lt;= ct_stop) )[0]
    time = time[inds]
    
    print(&#34;Requested start time was: &#34;+str(ct_start))
    print(&#34;Requested stop time was: &#34;+str(ct_stop))
    print(&#34;Actual start time is: &#34;+str(time[0]))
    print(&#34;Actual stop time is: &#34;+str(time[-1]))
        
    data = []
    for pol in pols:
        tag = &#39;pol{0}{0}.scio&#39;.format(pol)
        poldata = read_pol_fast(fnames, tag)
        data.append(poldata)

    for i in xrange(len(pols)):
        for j in xrange(i+1, len(pols)):
            for reality in [&#39;r&#39;, &#39;i&#39;]:
                tag = &#39;pol{}{}{}.scio&#39;.format(i,j,reality)
                poldata = read_pol_fast(fnames, tag)
                data.append(poldata)

    data = np.asarray(data)
    data = data[:,inds]

    return time, data</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.ctime2timestamp"><code class="name flex">
<span>def <span class="ident">ctime2timestamp</span></span>(<span>ctimes)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a (list of) ctime, convert to human friendly format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ctime</code></strong> :&ensp;<code>int</code> or <code>float</code> or <code>list</code> of <code>int/float</code></dt>
<dd>(List of) ctime(s).</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>list
The time stamps (or list of time stamps) in human friendly format.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ctime2timestamp(ctimes):
    &#34;&#34;&#34;Given a (list of) ctime, convert to human friendly format.

    Parameters
    ----------
    ctime: int or float or list of int/float
        (List of) ctime(s).

    Returns 
    -------
    list
        The time stamps (or list of time stamps) in human friendly format.
    &#34;&#34;&#34;

    if isinstance(ctimes, (int, float)):
        return str(datetime.datetime.utcfromtimestamp(ctimes))
    else:
        return [ str(datetime.datetime.utcfromtimestamp(c)) for c in ctimes ]</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.mallocdir"><code class="name flex">
<span>def <span class="ident">mallocdir</span></span>(<span>dir_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Allocate a directory without initializing it. (think calloc/malloc)</p>
<p>If a directory doesn't exist, create it; otherwise, leave it as it is. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dir_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory we want to allocate.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mallocdir(dir_name):
    &#34;&#34;&#34;Allocate a directory without initializing it. (think calloc/malloc)
    
    If a directory doesn&#39;t exist, create it; otherwise, leave it as it is. 
    
    Parameters
    ----------
    dir_name: str
        The path to the directory we want to allocate. 
    &#34;&#34;&#34;
    if os.path.exists(dir_name) == False:
        os.mkdir(dir_name)
    return</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.read_field_many_fast"><code class="name flex">
<span>def <span class="ident">read_field_many_fast</span></span>(<span>dirs, tag, dtype='float64', return_missing=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads one baseline from multiple data dumps. </p>
<p><em>Warning</em> Do both this function and read_pol_fast have different use
cases? The only difference I can see is that this one also has option
to return missing files, and is implemented slightly differently
(does not use scio [pbio]). </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dirs</code></strong> :&ensp;<code>list</code></dt>
<dd>List of paths to baseline data files.</dd>
<dt><strong><code>tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifies which polarization baseline. E.g. 'pol00'</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>Specifies numpy primitive data-type.</dd>
<dt><strong><code>return_missing</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, returns list of paths where data is missing as second
return parameter. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code> or <code>tuple[np.ndarray, list]</code></dt>
<dd>A numpy array containing all xcorr/autocorr baseline data
requested. If none was found, returns None. If return_missing
is True, returns a list of filepaths that point to non-existant
data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_field_many_fast(dirs,tag,dtype=&#39;float64&#39;,return_missing=False):
    &#34;&#34;&#34;Reads one baseline from multiple data dumps. 
    
    *Warning* Do both this function and read_pol_fast have different use 
    cases? The only difference I can see is that this one also has option 
    to return missing files, and is implemented slightly differently 
    (does not use scio [pbio]). 
    
    Parameters
    ----------
    dirs: list
        List of paths to baseline data files. 
    tag: str
        Identifies which polarization baseline. E.g. &#39;pol00&#39;
    dtype: str
        Specifies numpy primitive data-type. 
    return_missing: bool
        If True, returns list of paths where data is missing as second 
        return parameter. Defaults to False. 
    
    
    Returns
    -------
    np.ndarray or tuple[np.ndarray, list]
        A numpy array containing all xcorr/autocorr baseline data 
        requested. If none was found, returns None. If return_missing 
        is True, returns a list of filepaths that point to non-existant
        data. 
    &#34;&#34;&#34;
    ndir=len(dirs)
    all_dat=[None]*ndir
    missing=[]
    ndat=0
    for i in range(ndir):
        try:
            fname=dirs[i]+&#39;/&#39;+tag # todo: change to os.path.join(dirs[i], tag)
            all_dat[i]=np.fromfile(fname,dtype=dtype)
            ndat=ndat+len(all_dat[i])
        except:
            missing.append(fname)
    if ndat&gt;0:
        dat=np.zeros(ndat,dtype=dtype)
        ii=0
        for i in range(ndir):
            if not(all_dat[i] is None):
                nn=len(all_dat[i])
                if nn&gt;0:
                    dat[ii:ii+nn]=all_dat[i]
                    ii+=nn
        if return_missing:
            return dat,missing
        else:
            return dat
    else:
        if return_missing:
            return None,missing
        else:
            return None</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.read_pol_fast"><code class="name flex">
<span>def <span class="ident">read_pol_fast</span></span>(<span>dirs, tag)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads one baseline from multiple data dumps.</p>
<p>A baseline is identified by tag, the data is identified by dirs.
Relevant data are read and returned as a 2d numpy array. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dirs</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of paths to baseline data files.</dd>
<dt><strong><code>tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifies which polarization baseline. E.g. 'pol00'</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>big_dat</code></strong> :&ensp;<code>np.ndarray with shape (ndat, nchan)</code></dt>
<dd>A 2-d numpy array that stores all relevant data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_pol_fast(dirs,tag):
    &#34;&#34;&#34;Reads one baseline from multiple data dumps.
    
    A baseline is identified by tag, the data is identified by dirs. 
    Relevant data are read and returned as a 2d numpy array. 
    
    Parameters
    ----------
    dirs: list of str
        List of paths to baseline data files. 
    tag: str
        Identifies which polarization baseline. E.g. &#39;pol00&#39;
        
    Returns
    -------
    big_dat: np.ndarray with shape (ndat, nchan)
        A 2-d numpy array that stores all relevant data. 
    &#34;&#34;&#34;
    ndir=len(dirs)
    fnames=[None]*ndir
    for i in range(ndir):
        fnames[i]=dirs[i]+&#39;/&#39;+tag 
    # Once we have tests, above 4 lines can be condensed into: 
    # fnames = [os.path.join(d,tag) for d in dirs]
    t0=time.time()
    all_dat=scio.read_files(fnames) # all data files
    t1=time.time()
    print(&#39;read files in &#39;,t1-t0)
    ndat=0
    for dat in all_dat:
        if not(dat is None): # if dat is not None
            ndat=ndat+dat.shape[0]
            nchan=dat.shape[1]

    if ndat&gt;0:
        big_dat=np.zeros([ndat,nchan])
        ii=0
        for dat in all_dat:
            if not(dat is None):
                nn=dat.shape[0]
                big_dat[ii:(ii+nn),:]=dat
                ii=ii+nn
    else:
        print(&#39;No files found in read_pol_fast.&#39;)
        big_dat=None
    return big_dat</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.readin_append"><code class="name flex">
<span>def <span class="ident">readin_append</span></span>(<span>dir_names, base_file_path, file_name, function)</span>
</code></dt>
<dd>
<div class="desc"><p>Read multiple files fast. </p>
<p><em>Warning</em> This may be a duplicate of <code><a title="albatros_analysis.SNAPfiletools.read_field_many_fast" href="#albatros_analysis.SNAPfiletools.read_field_many_fast">read_field_many_fast()</a></code>. </p>
<p>Looks through multiple specified sub-directories of base_file_path
for leaves (files) with one specific name. Applies function to each
file. E.g. This method can be used to load multiple data from one
multiple files containing the same baseline (xcorr/autocorr) into
an array.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dir_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of relative directory names.</dd>
<dt><strong><code>base_file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the base file in which we search for sub-directories
'dir_names'.</dd>
<dt><strong><code>file_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the leaf node (file). A similar variable is refered to as
'tag' above.</dd>
<dt><strong><code>function</code></strong> :&ensp;<code>callable</code></dt>
<dd>Applied to filepath. Takes path-string and returns numpy array.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Most likely this will be used to read</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readin_append(dir_names, base_file_path, file_name, function):
    &#34;&#34;&#34;Read multiple files fast. 
    
    *Warning* This may be a duplicate of `read_field_many_fast`. 
    
    Looks through multiple specified sub-directories of base_file_path 
    for leaves (files) with one specific name. Applies function to each
    file. E.g. This method can be used to load multiple data from one 
    multiple files containing the same baseline (xcorr/autocorr) into 
    an array.
    
    Parameters
    ----------
    dir_names: list of str
        List of relative directory names. 
    base_file_path: str
        Path to the base file in which we search for sub-directories 
        &#39;dir_names&#39;. 
    file_name: str
        Name of the leaf node (file). A similar variable is refered to as 
        &#39;tag&#39; above. 
    function: callable
        Applied to filepath. Takes path-string and returns numpy array. 
    
    Returns
    -------
    data: np.ndarray
        Most likely this will be used to read 
    &#34;&#34;&#34;
    for index, dir_name in enumerate(dir_names):
        file_path = os.path.join(base_file_path, dir_name, file_name)
        if index ==0:
            data = function(file_path)
        else:
            data = np.append(data,function(file_path), axis = 0)
            # print(&#34;append so shape is now&#34;)
            # print(np.shape(data))
    # print(np.shape(data))
    return data </code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.readin_computed"><code class="name flex">
<span>def <span class="ident">readin_computed</span></span>(<span>fname)</span>
</code></dt>
<dd>
<div class="desc"><p>Read binary file into numpy array. </p>
<p><em>Warning</em>, this may be depricated (with
functionality contained within <code><a title="albatros_analysis.SNAPfiletools.read_pol_fast" href="#albatros_analysis.SNAPfiletools.read_pol_fast">read_pol_fast()</a></code> subroutine)</p>
<p>Thin wrapper for np.load().</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fname</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to binary file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>The binary array at fname.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readin_computed(fname):
    &#34;&#34;&#34;Read binary file into numpy array. 
    
    *Warning*, this may be depricated (with 
    functionality contained within `read_pol_fast` subroutine)
    
    Thin wrapper for np.load().
    
    Parameters
    ----------
    fname: str
        Path to binary file. 

    Returns
    -------
    np.ndarray
        The binary array at fname. 
    &#34;&#34;&#34;
    with open(fname, &#39;rb&#39;) as f:
        out = np.load(f)
    return out</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.time2fnames"><code class="name flex">
<span>def <span class="ident">time2fnames</span></span>(<span>time_start, time_stop, dir_parent, fraglen=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets a list of filenames within specified time-rage. </p>
<p>Given a start and stop ctime, retrieve list of corresponding files.
This function assumes that the parent directory has the directory
structure <dir_parent>/&lt;5-digit coarse time fragment&gt;/&lt;10-digit
fine time stamp&gt;.</p>
<h2 id="paramaters">Paramaters:</h2>
<p>time_start, time_stop: int
start/stop times in ctime </p>
<p>dir_parent: str
parent directory, e.g. /path/to/data_100MHz</p>
<p>fraglen: int
number of digits in coarse time fragments</p>
<h2 id="returns">Returns</h2>
<p>list of str
List of files in specified time range.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time2fnames(time_start, time_stop, dir_parent, fraglen=5):
    &#34;&#34;&#34;Gets a list of filenames within specified time-rage. 
    
    Given a start and stop ctime, retrieve list of corresponding files.
    This function assumes that the parent directory has the directory
    structure &lt;dir_parent&gt;/&lt;5-digit coarse time fragment&gt;/&lt;10-digit
    fine time stamp&gt;.

    Paramaters:
    -----------
    time_start, time_stop: int 
        start/stop times in ctime 
    
    dir_parent: str
        parent directory, e.g. /path/to/data_100MHz
    
    fraglen: int 
        number of digits in coarse time fragments
    
    Returns 
    -------
    list of str
        List of files in specified time range.
    &#34;&#34;&#34;

    times_coarse = os.listdir(dir_parent)
    times_coarse.sort()
    s = re.compile(r&#39;(\d{10})&#39;)  # We&#39;ll use this to search for 10-digit time strings
    fnames = []
    for time_coarse in times_coarse:
        try:
            # Include +-1 coarse directory on endpoints because
            # sometimes the fine time stamp rolls over to the coarse
            # time within the same directory
            if ((int(time_coarse) &lt; int(str(time_start)[:fraglen])-1) or (int(time_coarse) &gt; int(str(time_stop)[:fraglen])+1)):
                continue 
            
            all_fnames = os.listdir(&#39;{}/{}&#39;.format(dir_parent, time_coarse))
            all_fnames.sort()

            for f in all_fnames:
                if s.search(f):
                    tstamp = int(s.search(f).groups()[0])
                    if tstamp &gt;= time_start and tstamp &lt;= time_stop:
                        # fnames.append(dir_parent+&#39;/&#39;+time_coarse+&#39;/&#39;+f)
                        fnames.append(os.path.join(dir_parent,time_coarse,f))
        except:
            pass
    fnames.sort()
    return fnames</code></pre>
</details>
</dd>
<dt id="albatros_analysis.SNAPfiletools.timestamp2ctime"><code class="name flex">
<span>def <span class="ident">timestamp2ctime</span></span>(<span>date_strings, time_format='%Y%m%d_%H%M%S')</span>
</code></dt>
<dd>
<div class="desc"><p>Converts list of date strings into ctime format.</p>
<p>Given a string time stamp (or list of time stamps) in human-frendly
format, with default being YYYYMMSS_HHMMSS, convert to datetime
object and calculate ctime.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>date_strings</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Time stamp(s) in desired text format</dd>
<dt><strong><code>time_format</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Formatting string for datetime</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list </code></dt>
<dd>The time stamps (or list of time stamps) in ctime.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timestamp2ctime(date_strings, time_format=&#39;%Y%m%d_%H%M%S&#39;):
    &#34;&#34;&#34;Converts list of date strings into ctime format.
    
    Given a string time stamp (or list of time stamps) in human-frendly
    format, with default being YYYYMMSS_HHMMSS, convert to datetime
    object and calculate ctime.

    Parameters
    ----------
    date_strings: str or list of str
        Time stamp(s) in desired text format
    time_format: str or list of str
        Formatting string for datetime

    Returns
    -------
    list 
        The time stamps (or list of time stamps) in ctime.
     &#34;&#34;&#34;

    t0 = datetime.datetime(1970, 1, 1)

    if isinstance(date_strings, str):
        return int((datetime.datetime.strptime(date_strings, time_format) - t0).total_seconds())
    else:
        return [ int((datetime.datetime.strptime(d, time_format) - t0).total_seconds()) for d in date_strings ]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="albatros_analysis" href="index.html">albatros_analysis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="albatros_analysis.SNAPfiletools.callocdir" href="#albatros_analysis.SNAPfiletools.callocdir">callocdir</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.ctime2data" href="#albatros_analysis.SNAPfiletools.ctime2data">ctime2data</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.ctime2timestamp" href="#albatros_analysis.SNAPfiletools.ctime2timestamp">ctime2timestamp</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.mallocdir" href="#albatros_analysis.SNAPfiletools.mallocdir">mallocdir</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.read_field_many_fast" href="#albatros_analysis.SNAPfiletools.read_field_many_fast">read_field_many_fast</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.read_pol_fast" href="#albatros_analysis.SNAPfiletools.read_pol_fast">read_pol_fast</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.readin_append" href="#albatros_analysis.SNAPfiletools.readin_append">readin_append</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.readin_computed" href="#albatros_analysis.SNAPfiletools.readin_computed">readin_computed</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.time2fnames" href="#albatros_analysis.SNAPfiletools.time2fnames">time2fnames</a></code></li>
<li><code><a title="albatros_analysis.SNAPfiletools.timestamp2ctime" href="#albatros_analysis.SNAPfiletools.timestamp2ctime">timestamp2ctime</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>